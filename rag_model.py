
import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer

# 1Ô∏è‚É£ Load model (ye hi "brain" hai)
print("Loading model...")
model = SentenceTransformer("all-MiniLM-L6-v2")

# 2Ô∏è‚É£ JSON data load karo (Change: laws.json -> all_training_data.json)
print("Loading data...")
try:
    with open("all_training_data.json", "r", encoding="utf-8") as f:
        data = json.load(f)
except FileNotFoundError:
    print("Error: 'all_training_data.json' nahi mili. Please file name check karein.")
    exit()

# 3Ô∏è‚É£ Text documents banao (RAG-friendly)
documents = []
for item in data:
    text = f"""
    {item.get('input', '')}
    {item.get('output', '')}
    """
    documents.append(text)

# 4Ô∏è‚É£ Embeddings banao (memory ban rahi hai)
print("Encoding data (thoda time lagega)...")
embeddings = model.encode(documents, show_progress_bar=True)

# 5Ô∏è‚É£ Vector store (FAISS)
dim = embeddings.shape[1]
index = faiss.IndexFlatL2(dim)
# Fix: Ensure float32 for Faiss compatibility
index.add(np.array(embeddings).astype('float32'))

print("‚úÖ RAG memory ready")

# 6Ô∏è‚É£ User se question lo
while True:
    query = input("\n‚ùì Question pucho (exit likho band karne ke liye): ")
    if query.lower().strip() == "exit":
        break
    if not query.strip():
        continue

    # 7Ô∏è‚É£ Question embedding
    q_embedding = model.encode([query])

    # 8Ô∏è‚É£ Relevant law nikaalo
    # Fix: Ensure float32 for Faiss search
    _, idx = index.search(np.array(q_embedding).astype('float32'), k=2)
    context = "\n\n".join([documents[i] for i in idx[0]])

    # 9Ô∏è‚É£ Simple answer (abhi LLM nahi, sirf context show)
    print("\nüìå Relevant Law:")
    print(context)
